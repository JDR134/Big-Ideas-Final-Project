{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The best Neighborhood in Pittsburgh (For Squatting)\n",
    "\n",
    "While deliberating on what we could be used to define the best neighborhood in Pittbsurgh, we came to the conlucison that if we were ever to end up in a disadvantaged position and school did not work out for us, we should know where the best place for us to hide out would be. We wanted to know where we could go if we had no other options. With the data we had available to us we decided to analyze the Liklihood of Arrest for Trespassing, the Social Services available to us in a given neighborhood, and the Available Properties that could possibly be available for someone to squat in. Through weighing all these metrics would could cross reference what would be the best neighborhood for access to food, shelter, and avoiding law enforcement. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Access to Social Services\n",
    "While living wihtout a reliable support network its important to know what services are available to you that are provided by both governement and charitable foundations. This data set archived all Social Services available throguhout the City of Pittsbrugh and Alleghany County. For this set we organized every available service by the neighborhood they were in and ranked them from highest to lowest. As this data set contained data from outside the city, after the data was sorted we removed any instances from neighborhoods not in the city limits. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "services = pd.read_csv(\"5a05b9ec-2fbf-43f2-bfff-1de2555ff7d4.csv\")\n",
    "\n",
    "neighborhoodDictionary = {}\n",
    "\n",
    "neighborhoods = pd.DataFrame(services, columns=['neighborhood'])\n",
    "\n",
    "for i in range(len(neighborhoods)):\n",
    "    if neighborhoods.loc[i, 'neighborhood'] != \"Unknown\":\n",
    "        if neighborhoods.loc[i, 'neighborhood'].upper() not in neighborhoodDictionary:\n",
    "            neighborhoodDictionary[neighborhoods.loc[i, 'neighborhood'].upper()] = 1\n",
    "        else:\n",
    "            neighborhoodDictionary[neighborhoods.loc[i, 'neighborhood'].upper()] += 1\n",
    "neighborhoodDictionary.pop('WILKINSBURG')\n",
    "neighborhoodDictionary.pop(\"MCKEESPORT\")\n",
    "neighborhoodDictionary.pop(\"MCKEES ROCKS\")\n",
    "neighborhoodDictionary.pop(\"BRADDOCK\")\n",
    "neighborhoodDictionary.pop(\"SWISSVALE\")\n",
    "neighborhoodDictionary.pop(\"NATRONA HEIGHTS\")\n",
    "neighborhoodsValues = pd.DataFrame(list(neighborhoodDictionary.items()), columns=['Neighborhoods', 'Values'])\n",
    "final = neighborhoodsValues.sort_values(by=['Values'], ascending=False)\n",
    "final.head(10) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Available Properties\n",
    "This data set shows all publiclly available proprties in Pittsburgh that are owned by the City and up for sale. THe thought behind using this data is that the city has taken ownership of these proprties after forecloseres and evictions so any proprty listed here is likley to be vacant. Therefore if a neighborhood has a high amount of listings it can make it easier for someone to move between proprties and live in good a good shelter while evading detection or causing issues for residents. For this data we did not take into account total size of a given neighborhood as we decided what was more important was total availability and not strict density. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "houses = pd.read_csv('public-properties.csv',sep = ',') \n",
    "\n",
    "neighborhoods = {}\n",
    "for index, row in houses.iterrows():\n",
    "    key = row['Neighborhood']\n",
    "    \n",
    "    if key in neighborhoods:\n",
    "        neighborhoods[key] = int(neighborhoods[key] + 1)\n",
    "    else:\n",
    "        neighborhoods[key] = int(1)\n",
    "\n",
    "def my_filtering_function(pair):\n",
    "    key, value = pair\n",
    "    return value >= 10\n",
    " \n",
    "filtered_neighborhoods = dict(filter(my_filtering_function, neighborhoods.items()))\n",
    "filtered_neighborhoods = dict(sorted(filtered_neighborhoods.items(), key=lambda x:x[1], reverse=True))\n",
    "print(filtered_neighborhoods)\n",
    "\n",
    "filtered_neighborhoods_first20 = {k: filtered_neighborhoods[k] for k in list(filtered_neighborhoods)[:20]}\n",
    "keys = filtered_neighborhoods_first20.keys()\n",
    "values = filtered_neighborhoods_first20.values()\n",
    "plt.bar(keys, values)\n",
    "plt.xticks(rotation='vertical')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Likelihood of Arrest\n",
    "When evaluating the best neighborhood for suatting of course something to take into consideration is the likleihood of being arrested for trespassing. The data set used for this metric was the total arrests made by Pittsburgh police and their infraction type and location. To sort this data we first tallied up all the arrests made in a given neighborhood and then tallied up any arrests made for trespassing of any kind. With these two we then checked what percentage of the total arrests made in a neighborhood was for trespassing and ranked the neighborhoods from lowest to highest. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv(\"arrests.csv\")\n",
    "\n",
    "trespass_df = df[df['OFFENSES'].str.contains('TRESPASS', case=False, na=False)]\n",
    "trespass_counts = trespass_df['INCIDENTNEIGHBORHOOD'].value_counts().reset_index()\n",
    "trespass_counts.columns = ['INCIDENTNEIGHBORHOOD', 'TRESPASS_ARRESTS']\n",
    "total_arrests = df['INCIDENTNEIGHBORHOOD'].value_counts().reset_index()\n",
    "total_arrests.columns = ['INCIDENTNEIGHBORHOOD', 'TOTAL_ARRESTS']\n",
    "\n",
    "result_df = pd.merge(trespass_counts, total_arrests, on='INCIDENTNEIGHBORHOOD', how='left')\n",
    "\n",
    "result_df['PERCENT_TRESPASS'] = (result_df['TRESPASS_ARRESTS'] / result_df['TOTAL_ARRESTS']) * 100\n",
    "result_df.sort_values(by='PERCENT_TRESPASS', inplace=True)\n",
    "print(result_df)\n",
    "arrests = (result_df['TRESPASS_ARRESTS'].sum() / result_df['TOTAL_ARRESTS'].sum())\n",
    "print(\"Average Percent Trespass: \", arrests*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
